TORCH_DISTRIBUTED_DEBUG=DETAIL PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python AZFUSE_USE_FUSE=0 QD_USE_LINEIDX_8B=0 NCCL_ASYNC_ERROR_HANDLING=0 python -m torch.distributed.launch --nproc_per_node=4 --master_port=12311 finetune_sdm_yaml.py \
--cf config/ref_attn_clip_combine_controlnet_attr_pretraining/coco_S256_xformers_tsv_strongrand5.1.py \
--do_train --root_dir /home/nfs/jsh/DisCo \
--local_train_batch_size 4 --local_eval_batch_size 4 --log_dir exp/pretrain_5.1_dino_hd \
--epochs 600 --deepspeed --eval_step 500 --save_step 500 --gradient_accumulate_steps 1 \
--learning_rate 1e-3 --fix_dist_seed --loss_target "noise" \
--train_yaml /home/nfs/jsh/HOME/VITON-hd-resized/train/tsv/train.yaml \
--val_yaml /home/nfs/jsh/HOME/VITON-hd-resized/try/tsv/val.yaml \
--unet_unfreeze_type "transblocks"  --ref_null_caption True \
--combine_clip_local --combine_use_mask --viton_hd --no_smpl \
--conds "masks" --max_eval_samples 2000 --strong_aug_stage1 --node_split_sampler 0 